# -*- coding: utf-8 -*-
"""BLOOMBERG

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15iSHxMEtBegVT1VvFQskrCnWOWwyfpiz
"""

import pandas as pd
import numpy as np
from statsmodels.tsa.stattools import adfuller, coint
from statsmodels.tsa.arima.model import ARIMA
import matplotlib.pyplot as plt
from google.colab import files
import io

# Uploading Excel files for JPM, GOOG, and NVDA
print("Please upload the Excel files for JPM, GOOG, and NVDA")
uploaded = files.upload()

# Reading and preparing data from uploaded Excel files
def load_and_clean_data(file_name, close_col):
    try:
        df = pd.read_excel(io.BytesIO(uploaded[file_name]))
        df.columns = df.columns.str.strip()
        # Extracting the closing price column
        df_close = df[[close_col]].dropna()
        # Converting to numeric and handling errors
        df_close = df_close.apply(pd.to_numeric, errors='coerce').dropna()
        return df_close.reset_index(drop=True)
    except Exception as e:
        print(f"Error loading {file_name}: {str(e)}")
        return None

# Loading data for each stock
jpm_data = load_and_clean_data("1 min data.xlsx", "JPM Close")
goog_data = load_and_clean_data("1 min data.xlsx", "GOOG Close")
nvda_data = load_and_clean_data("1 min data.xlsx", "NVDA Close")

# Checking if data was loaded successfully
if jpm_data is None or goog_data is None or nvda_data is None:
    raise ValueError("Failed to load one or more data files. Please check the file format and column names.")

# Combining data into a single DataFrame for analysis
data = pd.concat([jpm_data, goog_data, nvda_data], axis=1)
data.columns = ['JPM_Close', 'GOOG_Close', 'NVDA_Close']
data = data.dropna()

# Performing ADF unit root tests
def perform_adf_test(series, name):
    result = adfuller(series, autolag='AIC')
    print(f"\nADF Test for {name}:")
    print(f"  p-value: {result[1]:.4f}")
    print(f"  Test Statistic: {result[0]:.4f}")
    print(f"  Critical Values: {result[4]}")
    return result[1]

adf_results = {}
for col in data.columns:
    adf_results[col] = perform_adf_test(data[col], col)

# Fitting ARMA(1,1) models (ARIMA with d=0)
def fit_arma_model(series, name):
    try:
        model = ARIMA(series, order=(1, 0, 1)).fit()
        print(f"\nARMA(1,1) Model Summary for {name}:")
        print(model.summary())
        return model
    except Exception as e:
        print(f"Error fitting ARMA model for {name}: {str(e)}")
        return None

models = {}
predictions = {}
for col in data.columns:
    models[col] = fit_arma_model(data[col], col)
    if models[col] is not None:
        predictions[col] = models[col].fittedvalues

# Plotting actual vs predicted values
def plot_arma_results(actual, predicted, title):
    plt.figure(figsize=(12, 5))
    plt.plot(actual, label='Actual', color='blue')
    plt.plot(predicted, label='ARMA(1,1) Predicted', linestyle='--', color='red')
    plt.title(f'ARMA(1,1) Model - {title}')
    plt.xlabel('Time')
    plt.ylabel('Price')
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.savefig(f'{title.lower().replace(" ", "_")}_arma_plot.png')
    plt.show()

for col in data.columns:
    if col in predictions:
        plot_arma_results(data[col], predictions[col], col.replace('_', ' '))

# Performing cointegration tests
def perform_cointegration_test(series1, series2, name1, name2):
    score, pvalue, _ = coint(series1, series2)
    print(f"\nCointegration Test: {name1} ~ {name2}")
    print(f"  p-value: {pvalue:.4f}")
    return pvalue

cointegration_results = []
pairs = [('JPM_Close', 'GOOG_Close'), ('JPM_Close', 'NVDA_Close'), ('GOOG_Close', 'NVDA_Close')]
for pair in pairs:
    pvalue = perform_cointegration_test(data[pair[0]], data[pair[1]],
                                      pair[0].replace('_Close', ''),
                                      pair[1].replace('_Close', ''))
    cointegration_results.append((pair, pvalue))

# Creating a summary table of predictions and residuals
results_df = data.copy()
for col in data.columns:
    if col in predictions:
        results_df[f'{col}_Pred'] = predictions[col]
        results_df[f'{col}_Resid'] = results_df[col] - results_df[f'{col}_Pred']

# Displaying summary statistics
print("\n--- Summary Statistics ---")
print(results_df.describe())

# Saving results to CSV
results_df.to_csv('arma_cointegration_results.csv')
files.download('arma_cointegration_results.csv')

# Highlighting an interesting fact
print("\n--- Interesting Fact ---")
min_pvalue = min([p for _, p in cointegration_results])
min_pair = [pair for pair, p in cointegration_results if p == min_pvalue][0]
print(f"The strongest evidence of cointegration is between {min_pair[0].replace('_Close', '')} and {min_pair[1].replace('_Close', '')} "
      f"with a p-value of {min_pvalue:.4f}, suggesting a potential long-term relationship between these stock prices.")

import pandas as pd
import numpy as np
from statsmodels.tsa.stattools import adfuller, coint
from statsmodels.tsa.arima.model import ARIMA
import matplotlib.pyplot as plt
from google.colab import files
import io

# Subir el archivo Excel
print("Por favor, sube el archivo Excel que contenga las columnas JPM Close, GOOG Close y NVDA Close")
uploaded = files.upload()

# Obtener el nombre del archivo cargado
file_name = list(uploaded.keys())[0]

# Cargar y preparar los datos desde un único archivo
def load_data_from_single_file(file_name):
    try:
        df = pd.read_excel(io.BytesIO(uploaded[file_name]))
        df.columns = df.columns.str.strip()  # Eliminar espacios en los nombres de columna

        required_cols = ["JPM Close", "GOOG Close", "NVDA Close"]
        for col in required_cols:
            if col not in df.columns:
                raise ValueError(f"La columna '{col}' no está en el archivo.")

        df = df[required_cols].dropna()
        df = df.apply(pd.to_numeric, errors='coerce').dropna()
        df.columns = ['JPM_Close', 'GOOG_Close', 'NVDA_Close']
        return df.reset_index(drop=True)

    except Exception as e:
        print(f"Error al cargar el archivo: {str(e)}")
        return None

# Cargar los datos
data = load_data_from_single_file(file_name)

if data is None:
    raise ValueError("No se pudieron cargar los datos correctamente. Verifica el archivo y los nombres de las columnas.")

# Test de raíz unitaria ADF
def perform_adf_test(series, name):
    result = adfuller(series, autolag='AIC')
    print(f"\nPrueba ADF para {name}:")
    print(f"  p-value: {result[1]:.4f}")
    print(f"  Test Statistic: {result[0]:.4f}")
    print(f"  Valores Críticos: {result[4]}")
    return result[1]

adf_results = {}
for col in data.columns:
    adf_results[col] = perform_adf_test(data[col], col)

# Ajustar modelos ARMA(1,1)
def fit_arma_model(series, name):
    try:
        model = ARIMA(series, order=(1, 0, 1)).fit()
        print(f"\nResumen del modelo ARMA(1,1) para {name}:")
        print(model.summary())
        return model
    except Exception as e:
        print(f"Error al ajustar ARMA para {name}: {str(e)}")
        return None

models = {}
predictions = {}
for col in data.columns:
    models[col] = fit_arma_model(data[col], col)
    if models[col] is not None:
        predictions[col] = models[col].fittedvalues

# Graficar resultados reales vs predichos
def plot_arma_results(actual, predicted, title):
    plt.figure(figsize=(12, 5))
    plt.plot(actual, label='Real', color='blue')
    plt.plot(predicted, label='ARMA(1,1) Predicho', linestyle='--', color='red')
    plt.title(f'Modelo ARMA(1,1) - {title}')
    plt.xlabel('Tiempo')
    plt.ylabel('Precio')
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.savefig(f'{title.lower().replace(" ", "_")}_arma_plot.png')
    plt.show()

for col in data.columns:
    if col in predictions:
        plot_arma_results(data[col], predictions[col], col.replace('_', ' '))

# Pruebas de cointegración entre pares
def perform_cointegration_test(series1, series2, name1, name2):
    score, pvalue, _ = coint(series1, series2)
    print(f"\nPrueba de cointegración: {name1} ~ {name2}")
    print(f"  p-value: {pvalue:.4f}")
    return pvalue

cointegration_results = []
pairs = [('JPM_Close', 'GOOG_Close'), ('JPM_Close', 'NVDA_Close'), ('GOOG_Close', 'NVDA_Close')]
for pair in pairs:
    pvalue = perform_cointegration_test(data[pair[0]], data[pair[1]],
                                        pair[0].replace('_Close', ''),
                                        pair[1].replace('_Close', ''))
    cointegration_results.append((pair, pvalue))

# Crear DataFrame con predicciones y residuales
results_df = data.copy()
for col in data.columns:
    if col in predictions:
        results_df[f'{col}_Pred'] = predictions[col]
        results_df[f'{col}_Resid'] = results_df[col] - results_df[f'{col}_Pred']

# Mostrar estadísticas resumen
print("\n--- Estadísticas Descriptivas ---")
print(results_df.describe())

# Guardar resultados a CSV
results_df.to_csv('arma_cointegration_results.csv')
files.download('arma_cointegration_results.csv')

# Dato interesante
print("\n--- Dato Interesante ---")
min_pvalue = min([p for _, p in cointegration_results])
min_pair = [pair for pair, p in cointegration_results if p == min_pvalue][0]
print(f"La evidencia más fuerte de cointegración es entre {min_pair[0].replace('_Close', '')} y {min_pair[1].replace('_Close', '')}, "
      f"con un p-valor de {min_pvalue:.4f}, lo que sugiere una posible relación a largo plazo entre estos precios.")